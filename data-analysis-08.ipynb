{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-08T14:12:31.311762Z","iopub.execute_input":"2022-11-08T14:12:31.312113Z","iopub.status.idle":"2022-11-08T14:12:31.320926Z","shell.execute_reply.started":"2022-11-08T14:12:31.312082Z","shell.execute_reply":"2022-11-08T14:12:31.319980Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"/kaggle/input/tourism-data/test/test.xlsx\n/kaggle/input/tourism-data/test/result1.csv\n/kaggle/input/tourism-data/train/2018-2019.xlsx\n/kaggle/input/tourism-data/train/2020-2021.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\nimport jieba\nimport re\n%matplotlib inline\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:31.426930Z","iopub.execute_input":"2022-11-08T14:12:31.427238Z","iopub.status.idle":"2022-11-08T14:12:31.434951Z","shell.execute_reply.started":"2022-11-08T14:12:31.427203Z","shell.execute_reply":"2022-11-08T14:12:31.433946Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Task 1","metadata":{}},{"cell_type":"code","source":"data1 = pd.read_excel('/kaggle/input/tourism-data/train/2018-2019.xlsx', sheet_name=4)\ndata2 = pd.read_excel('/kaggle/input/tourism-data/train/2020-2021.xlsx', sheet_name=4)\ntest_data = pd.read_excel('../input/tourism-data/test/test.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.370074Z","iopub.status.idle":"2022-11-08T14:12:20.373440Z","shell.execute_reply.started":"2022-11-08T14:12:20.373158Z","shell.execute_reply":"2022-11-08T14:12:20.373201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.374854Z","iopub.status.idle":"2022-11-08T14:12:20.375753Z","shell.execute_reply.started":"2022-11-08T14:12:20.375458Z","shell.execute_reply":"2022-11-08T14:12:20.375501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.377679Z","iopub.status.idle":"2022-11-08T14:12:20.379572Z","shell.execute_reply.started":"2022-11-08T14:12:20.379314Z","shell.execute_reply":"2022-11-08T14:12:20.379338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['ID', 'Title', 'Date', 'Content']\ndata1.columns = columns\ndata2.columns = columns","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.381737Z","iopub.status.idle":"2022-11-08T14:12:20.382417Z","shell.execute_reply.started":"2022-11-08T14:12:20.382136Z","shell.execute_reply":"2022-11-08T14:12:20.382161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([data1, data2], ignore_index=True)\ndata['Content'] = data['Title'] + '\\n' + data['Content']\ndata.drop(columns=['Title', 'Date'], inplace=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.384226Z","iopub.status.idle":"2022-11-08T14:12:20.385101Z","shell.execute_reply.started":"2022-11-08T14:12:20.384850Z","shell.execute_reply":"2022-11-08T14:12:20.384880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.386384Z","iopub.status.idle":"2022-11-08T14:12:20.390184Z","shell.execute_reply.started":"2022-11-08T14:12:20.389907Z","shell.execute_reply":"2022-11-08T14:12:20.389932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.391605Z","iopub.status.idle":"2022-11-08T14:12:20.396551Z","shell.execute_reply.started":"2022-11-08T14:12:20.396291Z","shell.execute_reply":"2022-11-08T14:12:20.396316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.columns = ['ID', 'Title', 'Content']\ntest_data['Content'] = test_data['Title'] + '\\n' + test_data['Content']\ntest_data.drop(columns=['Title'], inplace=True)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.397856Z","iopub.status.idle":"2022-11-08T14:12:20.398542Z","shell.execute_reply.started":"2022-11-08T14:12:20.398289Z","shell.execute_reply":"2022-11-08T14:12:20.398313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train data shape:', data.shape)\nprint('Test data shape:', test_data.shape)\ntrain_size = data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.400225Z","iopub.status.idle":"2022-11-08T14:12:20.400895Z","shell.execute_reply.started":"2022-11-08T14:12:20.400645Z","shell.execute_reply":"2022-11-08T14:12:20.400670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([data, test_data], ignore_index=True)\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.402432Z","iopub.status.idle":"2022-11-08T14:12:20.403005Z","shell.execute_reply.started":"2022-11-08T14:12:20.402765Z","shell.execute_reply":"2022-11-08T14:12:20.402788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(data):\n    try:\n        lines = data.split()\n    except Exception as e:\n        print(data)\n        return ''\n    lines = list(filter(lambda x: x is not '', lines))\n    unuse_lis = []\n    rule_1 = r'\\W'\n    compiled_rule_1 = re.compile(rule_1)\n    for line in lines:\n        no_en_and_da = compiled_rule_1.findall(line)\n        no_en_and_da_str = ''.join(no_en_and_da)\n        reslis = re.findall(r'^\\S', ''.join(re.findall(r'[^\\，]', ''.join(re.findall(r'[^\\。]', no_en_and_da_str)))))\n        unuse_lis.append(reslis)\n    syms = []\n    for i in unuse_lis:\n        for j in i:\n            syms.append(j)\n    syms = list(set(syms))\n    \n    def replace_syms(line):\n        for sym in syms:\n            line = line.replace(sym, '')\n        return line\n    \n    def replace_lem(line):\n        a = re.sub(r'\\s', '', line)\n        b = re.sub(r'\\W{2,}', '', a)\n        c = re.sub(r'\\d', '', b)\n        d = re.sub(r' ', '', c)\n        d = d.replace('_', '')\n        return d\n    \n    lines = list(map(replace_syms, lines))\n    lines = list(map(replace_lem, lines))\n    lines = list(filter(lambda x: x not in '1234567890', lines))\n    \n    res = []\n    for line in lines:\n        for word in jieba.cut(line):\n            if word == '，':\n                continue\n            res.append(word)\n    return ' '.join(res)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.408994Z","iopub.status.idle":"2022-11-08T14:12:20.409636Z","shell.execute_reply.started":"2022-11-08T14:12:20.409308Z","shell.execute_reply":"2022-11-08T14:12:20.409331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing(data.loc[0, 'Content'])","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.411120Z","iopub.status.idle":"2022-11-08T14:12:20.411731Z","shell.execute_reply.started":"2022-11-08T14:12:20.411490Z","shell.execute_reply":"2022-11-08T14:12:20.411513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Cut'] = data['Content'].apply(preprocessing)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.413465Z","iopub.status.idle":"2022-11-08T14:12:20.414011Z","shell.execute_reply.started":"2022-11-08T14:12:20.413763Z","shell.execute_reply":"2022-11-08T14:12:20.413786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.415754Z","iopub.status.idle":"2022-11-08T14:12:20.420577Z","shell.execute_reply.started":"2022-11-08T14:12:20.420273Z","shell.execute_reply":"2022-11-08T14:12:20.420298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 By LDA","metadata":{}},{"cell_type":"code","source":"data['AsList'] = data['Cut'].apply(lambda x: list(filter(lambda x: ' ' not in x, jieba.lcut(x))))\ndata['AsList'].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.421927Z","iopub.status.idle":"2022-11-08T14:12:20.422487Z","shell.execute_reply.started":"2022-11-08T14:12:20.422232Z","shell.execute_reply":"2022-11-08T14:12:20.422264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_data = data['AsList'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.424392Z","iopub.status.idle":"2022-11-08T14:12:20.424934Z","shell.execute_reply.started":"2022-11-08T14:12:20.424687Z","shell.execute_reply":"2022-11-08T14:12:20.424710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim import corpora\nfrom gensim.models import TfidfModel\n\ndictionary = corpora.Dictionary(text_data)\ndictionary.filter_n_most_frequent(200)\ncorpus = [dictionary.doc2bow(text) for text in text_data]\n\n# tfidf = TfidfModel(corpus)\n# tfidf.save('task_1_tfidf.model')\n# # corpus = tfidf[corpus]","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.426444Z","iopub.status.idle":"2022-11-08T14:12:20.427072Z","shell.execute_reply.started":"2022-11-08T14:12:20.426813Z","shell.execute_reply":"2022-11-08T14:12:20.426839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary.save('task_1.dict')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.432920Z","iopub.status.idle":"2022-11-08T14:12:20.433481Z","shell.execute_reply.started":"2022-11-08T14:12:20.433231Z","shell.execute_reply":"2022-11-08T14:12:20.433263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import LdaModel\n\n# Set training parameters.\nnum_topics = 10\nchunksize = 2000\npasses = 20\niterations = 200\neval_every = None  # Don't evaluate model perplexity, takes too much time.\n\n# Make a index to word dictionary.\ntemp = dictionary[0]  # This is only to \"load\" the dictionary.\nid2word = dictionary.id2token\n\nmodel = LdaModel(\n    corpus=corpus,\n    id2word=id2word,\n    chunksize=chunksize,\n    alpha='auto',\n    eta='auto',\n    iterations=iterations,\n    num_topics=num_topics,\n    passes=passes,\n    eval_every=eval_every\n)\n\nmodel.save('task_1.model')  # 将模型保存到硬盘","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.435135Z","iopub.status.idle":"2022-11-08T14:12:20.435826Z","shell.execute_reply.started":"2022-11-08T14:12:20.435589Z","shell.execute_reply":"2022-11-08T14:12:20.435613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_list = model.print_topics()\ntopic_list = sorted(topic_list, key=lambda x: x[0])\nprint(topic_list)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.437349Z","iopub.status.idle":"2022-11-08T14:12:20.437957Z","shell.execute_reply.started":"2022-11-08T14:12:20.437709Z","shell.execute_reply":"2022-11-08T14:12:20.437733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_topics = model.top_topics(corpus)\n\n# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\navg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\nprint('Average topic coherence: %.4f.' % avg_topic_coherence)\n\n# from pprint import pprint\n# pprint(top_topics)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.439537Z","iopub.status.idle":"2022-11-08T14:12:20.447526Z","shell.execute_reply.started":"2022-11-08T14:12:20.447262Z","shell.execute_reply":"2022-11-08T14:12:20.447288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_topics = []\nfor topic in top_topics:\n    topic_list, _ = topic\n    lda_topics.append([x[1] for x in topic_list])\nlda_topics","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.448929Z","iopub.status.idle":"2022-11-08T14:12:20.449680Z","shell.execute_reply.started":"2022-11-08T14:12:20.449424Z","shell.execute_reply":"2022-11-08T14:12:20.449449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_doc = text_data[23]\nprint(test_doc)\ndoc_bow = dictionary.doc2bow(test_doc)\n# doc_tfidf = tfidf[doc_bow]\ndoc_lda = model[doc_bow]\ndoc_lda","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.451060Z","iopub.status.idle":"2022-11-08T14:12:20.451844Z","shell.execute_reply.started":"2022-11-08T14:12:20.451574Z","shell.execute_reply":"2022-11-08T14:12:20.451599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def judge_coherence(doc):\n    coh_dict = ['旅游', '活动', '节庆', '特产', '交通', '酒店', '景区', '景点',\n                '文创', '文化', '乡村旅游', '民宿', '假日', '假期', '游客', '采摘',\n                '赏花', '春游', '踏青', '康养', '公园', '滨海游', '度假', '农家乐',\n                '剧本杀', '旅行', '徒步', '工业旅游', '线路', '自驾游', '团队游',\n                '攻略', '游记', '包车', '玻璃栈道', '游艇', '高尔夫', '温泉']\n    doc_bow = dictionary.doc2bow(test_doc)\n#     doc_tfidf = tfidf[doc_bow]\n    doc_lda = model[doc_bow]\n    topic_idx = [each[0] for each in doc_lda]\n    topics = []\n    for idx in topic_idx:\n        topics.extend(lda_topics[idx - 1])\n    \n    def judge(topics, coh_dict):\n        for x in topics:\n            for y in coh_dict:\n                if y in x:\n                    return True\n        return False\n    \n    return judge(topics, coh_dict)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.453313Z","iopub.status.idle":"2022-11-08T14:12:20.454107Z","shell.execute_reply.started":"2022-11-08T14:12:20.453833Z","shell.execute_reply":"2022-11-08T14:12:20.453858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text = text_data[train_size:]\ntest_res = [judge_coherence(text) for text in test_text]","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.455907Z","iopub.status.idle":"2022-11-08T14:12:20.456717Z","shell.execute_reply.started":"2022-11-08T14:12:20.456458Z","shell.execute_reply":"2022-11-08T14:12:20.456482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 By TF-IDF and TextRank","metadata":{}},{"cell_type":"code","source":"import jieba.analyse\n\ndef judge_by_tfidf(text):\n    coh_dict = ['旅游', '活动', '节庆', '特产', '交通', '酒店', '景区', '景点',\n                '文创', '文化', '乡村旅游', '民宿', '假日', '假期', '游客', '采摘',\n                '赏花', '春游', '踏青', '康养', '公园', '滨海游', '度假', '农家乐',\n                '剧本杀', '旅行', '徒步', '工业旅游', '线路', '自驾游', '团队游',\n                '攻略', '游记', '包车', '玻璃栈道', '游艇', '高尔夫', '温泉']\n    keywords = jieba.analyse.extract_tags(text, topK=50, withWeight=False)\n    for x in keywords:\n        for y in coh_dict:\n            if y in x:\n                return True\n    return False\n\ndef judge_by_textrank(text):\n    coh_dict = ['旅游', '活动', '节庆', '特产', '交通', '酒店', '景区', '景点',\n                '文创', '文化', '乡村旅游', '民宿', '假日', '假期', '游客', '采摘',\n                '赏花', '春游', '踏青', '康养', '公园', '滨海游', '度假', '农家乐',\n                '剧本杀', '旅行', '徒步', '工业旅游', '线路', '自驾游', '团队游',\n                '攻略', '游记', '包车', '玻璃栈道', '游艇', '高尔夫', '温泉']\n    keywords = jieba.analyse.textrank(text, topK=50, withWeight=False)\n    for x in keywords:\n        for y in coh_dict:\n            if y in x:\n                return True\n    return False\n\ndef judge(text):\n    return '相关' if judge_by_tfidf(text) and judge_by_textrank(text) else '不相关'\n\ntest_res = [judge(text) for text in data[train_size:]['Cut'].tolist()]","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.458190Z","iopub.status.idle":"2022-11-08T14:12:20.465541Z","shell.execute_reply.started":"2022-11-08T14:12:20.465272Z","shell.execute_reply":"2022-11-08T14:12:20.465299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"task1_res = pd.DataFrame({'文章ID': test_data['ID'].tolist(), \n                          '分类标签': test_res})\ntask1_res.to_csv('result1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:20.466952Z","iopub.status.idle":"2022-11-08T14:12:20.467736Z","shell.execute_reply.started":"2022-11-08T14:12:20.467476Z","shell.execute_reply":"2022-11-08T14:12:20.467502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2","metadata":{}},{"cell_type":"code","source":"def read_in(path):\n    sheet0 = pd.read_excel(path, sheet_name=0)\n    sheet1 = pd.read_excel(path, sheet_name=1)\n    sheet2 = pd.read_excel(path, sheet_name=2)\n    sheet3 = pd.read_excel(path, sheet_name=3)\n    sheet0.columns = ['ID', 'City', 'Name', 'RevDate', 'Content', 'CheckDate', 'HouseType']\n    sheet0['ID'] = sheet0['ID'].apply(lambda x: '酒店评论-' + str(x))\n    sheet0 = sheet0[['ID', 'Content']]\n    sheet1.columns = ['ID', 'City', 'Name', 'Date', 'Content']\n    sheet1['ID'] = sheet1['ID'].apply(lambda x: '景区评论-' + str(x))\n    indices = sheet1[sheet1['Name'].str.contains('湛江|广东海洋大学|南极长城站')].index\n    sheet1.drop(index=indices, inplace=True)\n    sheet1 = sheet1[['ID', 'Content']]\n    sheet2 = sheet2[['游记ID', '正文']]\n    sheet2.columns = ['ID', 'Content']\n    sheet2['ID'] = sheet2['ID'].apply(lambda x: '游记-' + str(x))\n    sheet3 = sheet3[['餐饮评论ID', '评论内容', '标题']]\n    sheet3.columns = ['ID', 'Content', 'Title']\n    sheet3['Content'] = sheet3['Title'] + '\\n' + sheet3['Content']\n    sheet3.drop(columns='Title', inplace=True)\n    sheet3['ID'] = sheet3['ID'].apply(lambda x: '餐饮评论-' + str(x))\n    ret = pd.concat([sheet0, sheet1, sheet2, sheet3], ignore_index=True)\n    return ret","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:15:42.156573Z","iopub.execute_input":"2022-11-08T14:15:42.156930Z","iopub.status.idle":"2022-11-08T14:15:42.168218Z","shell.execute_reply.started":"2022-11-08T14:15:42.156900Z","shell.execute_reply":"2022-11-08T14:15:42.167242Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"data1 = read_in('../input/tourism-data/train/2018-2019.xlsx')\ndata2 = read_in('../input/tourism-data/train/2020-2021.xlsx')\ndata = pd.concat([data1, data2], ignore_index=True)\ndata.head(), data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:37.243412Z","iopub.execute_input":"2022-11-08T14:12:37.243764Z","iopub.status.idle":"2022-11-08T14:12:42.081339Z","shell.execute_reply.started":"2022-11-08T14:12:37.243729Z","shell.execute_reply":"2022-11-08T14:12:42.080231Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(          ID                                            Content\n 0  酒店评论-1001                                            干净卫生服务好\n 1  酒店评论-1002                                           环境可以，干净！\n 2  酒店评论-1003  环境不错，房间卫生都很好，生活也很方便，就是隔音效果不理想，有时太吵。我定的优惠价，性价比很...\n 3  酒店评论-1004                                    很好.......舒服态度不错\n 4  酒店评论-1005                                 #卫生# #设计风格# #酒店餐饮#,\n (9496, 2))"},"metadata":{}}]},{"cell_type":"code","source":"data['Content'] = data['Content'].apply(lambda x: re.sub(r'^.*?\\n\\d+\\-\\d+\\-\\d+.*?\\nhttp.*?\\n|\\n.*?\\d+\\-\\d+\\-\\d+.*?\\nhttp.*?\\n|\\d+\\-\\d+\\-\\d+.*?\\nhttp.*?\\n| ', '', x))\ndata['Content'].dropna()\ndata.head(), data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:42.083147Z","iopub.execute_input":"2022-11-08T14:12:42.083997Z","iopub.status.idle":"2022-11-08T14:12:42.169538Z","shell.execute_reply.started":"2022-11-08T14:12:42.083958Z","shell.execute_reply":"2022-11-08T14:12:42.168695Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(          ID                                            Content\n 0  酒店评论-1001                                            干净卫生服务好\n 1  酒店评论-1002                                           环境可以，干净！\n 2  酒店评论-1003  环境不错，房间卫生都很好，生活也很方便，就是隔音效果不理想，有时太吵。我定的优惠价，性价比很...\n 3  酒店评论-1004                                    很好.......舒服态度不错\n 4  酒店评论-1005                                   #卫生##设计风格##酒店餐饮#,\n (9496, 2))"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install pyhanlp\n# !pip install foolnltk\n# !pip install tensorflow==1.14","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:53.241876Z","iopub.execute_input":"2022-11-08T14:12:53.242358Z","iopub.status.idle":"2022-11-08T14:12:53.247551Z","shell.execute_reply.started":"2022-11-08T14:12:53.242316Z","shell.execute_reply":"2022-11-08T14:12:53.246522Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from pyhanlp import *\nimport fool\n\ndata['Content'] = data['Content'].apply(HanLP.convertToSimplifiedChinese)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:12:53.774461Z","iopub.execute_input":"2022-11-08T14:12:53.774826Z","iopub.status.idle":"2022-11-08T14:12:53.996133Z","shell.execute_reply.started":"2022-11-08T14:12:53.774795Z","shell.execute_reply":"2022-11-08T14:12:53.995217Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"task2_1 = pd.DataFrame(columns=['ID', 'pID', 'Name'])\ncnt = 1\n\ndef judge(entity: str):\n    if str.__contains__(entity, '国') or str.__contains__(entity, '市') or str.__contains__(entity, '区') or str.__contains__(entity, '州'):\n        return False\n    if entity in ['茂名', '湛江', '河东', '粤西', '水东']:\n        return False\n    if entity in ['河北', '山西', '辽宁', '吉林', '黑龙江', \n                  '江苏', '浙江', '安徽', '福建', '江西', \n                  '山东', '河南', '湖北', '湖南', '广东', \n                  '海南', '四川', '贵州', '云南', '陕西', \n                  '甘肃', '青海', '台湾', '内蒙古', '广西', \n                  '西藏', '宁夏', '新疆', '北京', '天津', \n                  '上海', '重庆', '香港', '澳门']:\n        return False\n    return True\n\nfor index, row in data.iterrows():\n    ID, text = row['ID'], row['Content']\n    res = fool.analysis(text)[1][0]\n    if res != []:\n        for each in res:\n            _, _, type_, entity = each\n            if type_ == 'location' and judge(entity):\n                entity = entity.strip()\n                entity = entity.replace(' ', '')\n                entity = entity.replace('\\n', '')\n                task2_1.loc[cnt - 1, 'ID'] = ID\n                task2_1.loc[cnt - 1, 'pID'] = 'ID' + str(cnt)\n                task2_1.loc[cnt - 1, 'Name'] = entity\n                cnt += 1\ntask2_1.columns = ['语料ID', '产品ID', '产品名称']\ntask2_1.to_csv('result2-1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T14:29:45.580633Z","iopub.execute_input":"2022-11-08T14:29:45.581005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}